<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Web Scraping with Python: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<script src="assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="assets/styles.css">
<script src="assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="favicons/incubator/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicons/incubator/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicons/incubator/favicon-16x16.png">
<link rel="manifest" href="favicons/incubator/site.webmanifest">
<link rel="mask-icon" href="favicons/incubator/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="white">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="black">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Lesson Description" src="assets/images/incubator-logo.svg"><span class="badge text-bg-danger">
          <abbr title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.">
            <a href="https://docs.carpentries.org/resources/curriculum/lesson-life-cycle.html" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
              Pre-Alpha
            </a>
            <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text">
<li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul>
</li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Learner View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='instructor/aio.html';">Instructor View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Lesson Description" src="assets/images/incubator-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      Web Scraping with Python
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            Web Scraping with Python
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="reference.html#glossary">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="profiles.html">Learner Profiles</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul>
</li>
      </ul>
</div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Web Scraping with Python
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text">
<li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul>
</li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Learner View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="instructor/aio.html">Instructor View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->

            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Setup</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="hello-scraping.html">1. Hello-Scraping</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="a-real-website.html">2. Scraping a real website</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="dynamic-websites.html">3. Dynamic websites</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="reference.html#glossary">Glossary</a>
                      </li>
                      <li>
                        <a href="profiles.html">Learner Profiles</a>
                      </li>
                      <li><a href="reference.html">Reference</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources">
<a href="aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">

            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-hello-scraping"><p>Content from <a href="hello-scraping.html">Hello-Scraping</a></p>
<hr>
<p>Last updated on 2025-06-10 |

        <a href="https://github.com/josenino95/web-scraping-python/edit/main/episodes/hello-scraping.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What’s behind a website, and how can I extract information from
it?</li>
<li>What ethical and legal considerations should I keep in mind before
scraping a website?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Identify the structure and key components of an HTML document.</li>
<li>Use BeautifulSoup to locate elements, tags, attributes, and text
within an HTML page.</li>
<li>Recognize situations where web scraping is inappropriate or not
permitted for accessing data.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<hr class="half-width">
<p>This workshop is a continuation of our Introduction to Web Scraping
workshop. If you’re looking for a gentler introduction that uses XPath
and the Scraper Chrome extension, take a look at the <a href="https://carpentries-incubator.github.io/lc-webscraping/" class="external-link">workshop
materials for that workshop</a>.</p>
<p>Here, we’ll revisit some of those core ideas to build a more hands-on
understanding of how content and data are structured on the web. We’ll
start by exploring what HTML (Hypertext Markup Language) is and how it
uses tags to organize and format content. Then, we’ll introduce the
BeautifulSoup library to parse HTML and make it easier to search for and
extract specific elements from a webpage.</p>
<p>We’ll begin with simple examples and gradually move on to scraping
more complex, real-world websites.</p>
</section><section><h2 class="section-heading" id="html-quick-overview">HTML quick overview<a class="anchor" aria-label="anchor" href="#html-quick-overview"></a>
</h2>
<hr class="half-width">
<p>All websites have a Hypertext Markup Language (HTML) document behind
them. Below is an example of HTML for a very simple webpage that
contains just three sentences. As you look through it, try to imagine
how the website would appear in a browser.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">HTML<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode html" tabindex="0"><code class="sourceCode html"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="dt">&lt;!DOCTYPE</span> html<span class="dt">&gt;</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">html</span><span class="dt">&gt;</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">head</span><span class="dt">&gt;</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">title</span><span class="dt">&gt;</span>Sample web page<span class="dt">&lt;/</span><span class="kw">title</span><span class="dt">&gt;</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">head</span><span class="dt">&gt;</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">body</span><span class="dt">&gt;</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">h1</span><span class="dt">&gt;</span>h1 Header #1<span class="dt">&lt;/</span><span class="kw">h1</span><span class="dt">&gt;</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">p</span><span class="dt">&gt;</span>This is a paragraph tag<span class="dt">&lt;/</span><span class="kw">p</span><span class="dt">&gt;</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">h2</span><span class="dt">&gt;</span>h2 Sub-header<span class="dt">&lt;/</span><span class="kw">h2</span><span class="dt">&gt;</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">p</span><span class="dt">&gt;</span>A new paragraph, now in the <span class="dt">&lt;</span><span class="kw">b</span><span class="dt">&gt;</span>sub-header<span class="dt">&lt;/</span><span class="kw">b</span><span class="dt">&gt;&lt;/</span><span class="kw">p</span><span class="dt">&gt;</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">h1</span><span class="dt">&gt;</span>h1 Header #2<span class="dt">&lt;/</span><span class="kw">h1</span><span class="dt">&gt;</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">p</span><span class="dt">&gt;</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>This other paragraph has two hyperlinks,</span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>one to <span class="dt">&lt;</span><span class="kw">a</span><span class="ot"> href</span><span class="op">=</span><span class="st">"https://carpentries.org/"</span><span class="dt">&gt;</span>The Carpentries homepage<span class="dt">&lt;/</span><span class="kw">a</span><span class="dt">&gt;</span>,</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a>and another to the</span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">a</span><span class="ot"> href</span><span class="op">=</span><span class="st">"https://carpentries.org/workshops/past-workshops/"</span><span class="dt">&gt;</span>past workshops<span class="dt">&lt;/</span><span class="kw">a</span><span class="dt">&gt;</span> page.</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">p</span><span class="dt">&gt;</span></span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">body</span><span class="dt">&gt;</span></span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">html</span><span class="dt">&gt;</span></span></code></pre>
</div>
<p>If you save that text in a file with a .html extension —using a
simple text editor like Notepad on Windows or TextEdit on macOS— and
open it in your web browser, the browser will interpret the markup
language and display a nicely formatted web page.</p>
<figure><img src="fig/simple_website.PNG" alt="Screenshot of a simple website with the previews HTML" class="figure mx-auto d-block"></figure><p>When you open an HTML file in your browser, what it’s really doing is
reading a structured document made up of <strong>elements</strong>, each
marked by <strong>tags</strong> inside angle brackets (&lt; and &gt;).
For instance, the HTML root element, which delimits the beginning and
end of an HTML document, is identified by the <code>&lt;html&gt;</code>
tag.</p>
<p>Most elements have both an opening tag and a closing tag, which
define the start and end of that element. For example, in the simple
website we looked at earlier, the head element begins with
<code>&lt;head&gt;</code> and ends with <code>&lt;/head&gt;</code>.</p>
<p>Because elements can be nested inside one another, an HTML document
forms a tree structure, where each element is a node that can contain
child nodes, as illustrated in the image below.</p>
<figure><img src="https://upload.wikimedia.org/wikipedia/commons/5/5a/DOM-model.svg" alt="Screenshot of a simple website with the previews HTML" class="figure mx-auto d-block"><div class="figcaption">The Document Object Model (DOM) that represents
an HTML document with a tree structure. Source: Wikipedia. Author:
Birger Eriksson</div>
</figure><p>Finally, we can define or modify the behavior, appearance, or
functionality of an element using <strong>attributes</strong>.
Attributes appear inside the opening tag and consist of a name and a
value, formatted like <code>name="value"</code>.</p>
<p>For example, in the simple website, we added a hyperlink using the
<code>&lt;a&gt;...&lt;/a&gt;</code> tags. To specify the destination
URL, we used the <code>href</code> attribute inside the opening
<code>&lt;a&gt;</code> tag like this:
<code>&lt;a href="https://carpentries.org/workshops/past-workshops/"&gt;past workshops&lt;/a&gt;</code>.</p>
<p>Here is a non-exhaustive list of common HTML elements and their
purposes:</p>
<ul>
<li>
<code>&lt;hmtl&gt;...&lt;/html&gt;</code>: The root element that
contains the entire document.</li>
<li>
<code>&lt;head&gt;...&lt;/head&gt;</code>: Contains metadata such as
the page title that the browser displays.</li>
<li>
<code>&lt;body&gt;...&lt;/body&gt;</code>: Contains the content that
will be shown on the webpage.</li>
<li>
<code>&lt;h1&gt;...&lt;/h1&gt;, &lt;h2&gt;...&lt;/h2&gt;, &lt;h3&gt;...&lt;/h3&gt;</code>:
Define headers of levels 1, 2, 3, and so on.</li>
<li>
<code>&lt;p&gt;...&lt;/p&gt;</code>: Represents a paragraph.</li>
<li>
<code>&lt;a href=""&gt;...&lt;/a&gt;</code>: Creates a hyperlink;
the destination URL is set with the href attribute.</li>
<li>
<code>&lt;img src="" alt=""&gt;</code>: Embeds an image, with the
image source specified by <code>src</code> and alternative text provided
by <code>alt</code>. It doesn’t have an opening tag.</li>
<li>
<code>&lt;table&gt;...&lt;/table&gt;, &lt;th&gt;...&lt;/th&gt;, &lt;tr&gt;...&lt;/tr&gt;, &lt;td&gt;...&lt;/td&gt;</code>:
Define a table structure, with headers (<code>&lt;th&gt;</code>), rows
(<code>&lt;tr&gt;</code>), and cells (<code>&lt;td&gt;</code>).</li>
<li>
<code>&lt;div&gt;...&lt;/div&gt;</code>: Groups sections of HTML
content together.</li>
<li>
<code>&lt;script&gt;...&lt;/script&gt;</code>: Embeds or links to
JavaScript code.</li>
</ul>
<p>In the list above, we mentioned some attributes specific to hyperlink
(<code>&lt;a&gt;</code>) and image (<code>&lt;img&gt;</code>) elements,
but there are also several global attributes that most HTML elements can
have. These are especially useful for identifying elements when web
scraping:</p>
<ul>
<li>
<code>id=""</code>: Assigns a unique identifier to an element; this
ID must be unique within the entire HTML document.</li>
<li>
<code>title=""</code>: Provides extra information about the element,
shown as a tooltip when the user hovers over it.</li>
<li>
<code>class=""</code>: Applies a common styling or grouping to
multiple elements at once.</li>
</ul>
<p>To summarize: <strong>elements</strong> are identified by
<strong>tags</strong>, and <strong>attributes</strong> let us assign
properties or identifiers to those elements. Understanding this
structure will make it much easier to extract specific data from a
website.</p>
</section><section><h2 class="section-heading" id="parsing-html-with-beautifulsoup">Parsing HTML with BeautifulSoup<a class="anchor" aria-label="anchor" href="#parsing-html-with-beautifulsoup"></a>
</h2>
<hr class="half-width">
<p>Now that we understand how a website is structured, we can begin
extracting information from it. The <code>BeautifulSoup</code> package
is our main tool for this task —it parses the HTML so we can
programmatically search for and access the elements we need.</p>
<p>To see how BeautifulSoup works, we’ll use the simple website example
from earlier. As a first step, we’ll load the <code>BeautifulSoup</code>
package along with Pandas.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span></code></pre>
</div>
<p>Let’s store the HTML content in a string variable named
<code>example_html</code>.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>example_html <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="st">&lt;!DOCTYPE html&gt;</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="st">&lt;html&gt;</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="st">&lt;head&gt;</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="st">&lt;title&gt;Sample web page&lt;/title&gt;</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="st">&lt;/head&gt;</span></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="st">&lt;body&gt;</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="st">&lt;h1&gt;h1 Header #1&lt;/h1&gt;</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="st">&lt;p&gt;This is a paragraph tag&lt;/p&gt;</span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="st">&lt;h2&gt;h2 Sub-header&lt;/h2&gt;</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="st">&lt;p&gt;A new paragraph, now in the &lt;b&gt;sub-header&lt;/b&gt;&lt;/p&gt;</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a><span class="st">&lt;h1&gt;h1 Header #2&lt;/h1&gt;</span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a><span class="st">&lt;p&gt;</span></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a><span class="st">This other paragraph has two hyperlinks,</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a><span class="st">one to &lt;a href="https://carpentries.org/"&gt;The Carpentries homepage&lt;/a&gt;,</span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a><span class="st">and another to the</span></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a><span class="st">&lt;a href="https://carpentries.org/workshops/past-workshops/"&gt;past workshops&lt;/a&gt; page.</span></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a><span class="st">&lt;/p&gt;</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a><span class="st">&lt;/body&gt;</span></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a><span class="st">&lt;/html&gt;</span></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a><span class="st">"""</span></span></code></pre>
</div>
<p>We parse the HTML by passing it to the <code>BeautifulSoup()</code>
function, specifying <code>html.parser</code> as the parser. This
creates an object that represents the document as a nested data
structure —similar to the tree structure we discussed earlier. Using the
<code>.prettify()</code> method on this object displays the HTML with
indentation that reflects its nested structure, making it easier to
read.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>soup <span class="op">=</span> BeautifulSoup(example_html, <span class="st">'html.parser'</span>)</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="bu">print</span>(soup.prettify())</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
 &lt;head&gt;
  &lt;title&gt;
   Sample web page
  &lt;/title&gt;
 &lt;/head&gt;
 &lt;body&gt;
  &lt;h1&gt;
   h1 Header #1
  &lt;/h1&gt;
  &lt;p&gt;
   This is a paragraph tag
  &lt;/p&gt;
  &lt;h2&gt;
   h2 Sub-header
  &lt;/h2&gt;
  &lt;p&gt;
   A new paragraph, now in the
   &lt;b&gt;
    sub-header
   &lt;/b&gt;
  &lt;/p&gt;
  &lt;h1&gt;
   h1 Header #2
  &lt;/h1&gt;
  &lt;p&gt;
   This other paragraph has two  hyperlinks, one to
   &lt;a href="https://carpentries.org/"&gt;
    The Carpentries homepage
   &lt;/a&gt;
   , and another to the
   &lt;a href="https://carpentries.org/workshops/past-workshops/"&gt;
    past workshops
   &lt;/a&gt;
   .
  &lt;/p&gt;
 &lt;/body&gt;
&lt;/html&gt;</code></pre>
</div>
<p>Now that our <code>soup</code> variable holds the parsed document, we
can use the <code>.find()</code> and <code>.find_all()</code> methods to
search for elements.</p>
<ul>
<li><p><code>.find()</code> looks for the first occurrence of a
specified tag and returns the entire element, including its opening and
closing tags.</p></li>
<li><p>If multiple elements share the same tag, <code>.find()</code>
returns only the first one.</p></li>
<li><p>To get all matching elements, use <code>.find_all()</code>, which
returns a list of all elements with the specified tag.</p></li>
<li><p>To extract just the text inside an element and all its children,
use the <code>.get_text()</code> method. <code>.find()</code> will
search the tag that we specify, and return the entire element, including
the starting and closing tags.</p></li>
</ul>
<p>Below, you’ll see examples of how these commands work with our simple
website.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"1."</span>, soup.find(<span class="st">'title'</span>))</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"2."</span>, soup.find(<span class="st">'title'</span>).get_text())</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"3."</span>, soup.find(<span class="st">'h1'</span>).get_text())</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"4."</span>, soup.find_all(<span class="st">'h1'</span>))</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"5."</span>, soup.find_all(<span class="st">'a'</span>))</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"6."</span>, soup.get_text())</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>1. &lt;title&gt;Sample web page&lt;/title&gt;
2. Sample web page
3. h1 Header #1
4. [&lt;h1&gt;h1 Header #1&lt;/h1&gt;, &lt;h1&gt;h1 Header #2&lt;/h1&gt;]
5. [&lt;a href="https://carpentries.org/"&gt;The Carpentries homepage&lt;/a&gt;, &lt;a href="https://carpentries.org/workshops/past-workshops/"&gt;past workshops&lt;/a&gt;]
6.

Sample web page


h1 Header #1
This is a paragraph tag
h2 Sub-header
A new paragraph, now in the sub-header
h1 Header #2

This other paragraph has two hyperlinks,
one to The Carpentries homepage,
and another to the
past workshops page.</code></pre>
</div>
<p>How would you extract all hyperlinks identified with
<code>&lt;a&gt;</code> tags? In our example, we see that there are only
two hyperlinks, and we could extract them in a list using the
<code>.find_all('a')</code> method.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>links <span class="op">=</span> soup.find_all(<span class="st">'a'</span>)</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of hyperlinks found: "</span>, <span class="bu">len</span>(links))</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="bu">print</span>(links)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Number of hyperlinks found:  2
[&lt;a href="https://carpentries.org/"&gt;The Carpentries homepage&lt;/a&gt;, &lt;a href="https://carpentries.org/workshops/past-workshops/"&gt;past workshops&lt;/a&gt;]</code></pre>
</div>
<p>To access the value of a given attribute in an element, for example
the value of the <code>href</code> attribute in
<code>&lt;a href=""&gt;</code>, we would use the <code>.get()</code>
method with the name of the attribute (i.e. <code>.get('href')</code>).
Let’s make a loop that prints only the URL for each hyperlink we have in
our example.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="cf">for</span> item <span class="kw">in</span> links:</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>    <span class="bu">print</span>(item.get(<span class="st">'href'</span>))</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>https://carpentries.org/
https://carpentries.org/workshops/past-workshops/</code></pre>
</div>
<div id="challenge1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Create a Python dictionary that has the following three items,
containing information about the <strong>first</strong> hyperlink in the
HTML of our example.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>first_link <span class="op">=</span> {</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>   <span class="st">'element'</span>: the complete hyperlink element,</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>   <span class="st">'url'</span>: the destination url of the hyperlink,</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>   <span class="st">'text'</span>: the text that the website displays <span class="im">as</span> the hyperlink</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>}</span></code></pre>
</div>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>One way of completing the exercise is as follows.</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>first_link <span class="op">=</span> {</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>   <span class="st">'element'</span>: <span class="bu">str</span>(soup.find(<span class="st">'a'</span>)),</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>   <span class="st">'url'</span>: soup.find(<span class="st">'a'</span>).get(<span class="st">'href'</span>),</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>   <span class="st">'text'</span>: soup.find(<span class="st">'a'</span>).get_text()</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>}</span></code></pre>
</div>
<p>An alternative and often more efficient approach is to first store
the result of <code>soup.find('a')</code> in a variable, rather than
calling it multiple times. This makes your code cleaner and avoids
redundant searches.</p>
<p>You can also start by creating an empty dictionary and then add
key-value pairs to it. This is especially useful when you’re extracting
multiple pieces of information in a loop, as you’ll likely want to build
up a dictionary of results step by step.</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>find_a <span class="op">=</span> soup.find(<span class="st">'a'</span>)</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>first_link <span class="op">=</span> {}</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>first_link[<span class="st">'element'</span>] <span class="op">=</span> <span class="bu">str</span>(find_a)</span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>first_link[<span class="st">'url'</span>] <span class="op">=</span> find_a.get(<span class="st">'href'</span>)</span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>first_link[<span class="st">'text'</span>] <span class="op">=</span> find_a.get_text()</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<p>To wrap up this introduction to HTML and BeautifulSoup, let’s write
code that extracts all hyperlink elements in a structured way —capturing
each link’s tag, destination URL, and display text.</p>
<p>We’ll start with the links variable we created earlier:
<code>links = soup.find_all('a')</code>. Then, we’ll loop through each
hyperlink element, store the three pieces of information in a
dictionary, and append each dictionary to a list called
<code>list_of_dicts</code>. At the end, we’ll have a list containing two
dictionaries —one for each link— which we can easily convert into a
Pandas DataFrame.</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>links <span class="op">=</span> soup.find_all(<span class="st">'a'</span>)</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>list_of_dicts <span class="op">=</span> []</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a><span class="cf">for</span> item <span class="kw">in</span> links:</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>    dict_a <span class="op">=</span> {}</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>    dict_a[<span class="st">'element'</span>] <span class="op">=</span> <span class="bu">str</span>(item)</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a>    dict_a[<span class="st">'url'</span>] <span class="op">=</span> item.get(<span class="st">'href'</span>)</span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>    dict_a[<span class="st">'text'</span>] <span class="op">=</span> item.get_text()</span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a>    list_of_dicts.append(dict_a)</span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a>links_df <span class="op">=</span> pd.DataFrame(list_of_dicts)</span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a><span class="bu">print</span>(links_df)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>                                             element                                                url                      text
0  &lt;a href="https://carpentries.org/"&gt;The Carpent...                           https://carpentries.org/  The Carpentries homepage
1  &lt;a href="https://carpentries.org/workshops/pas...  https://carpentries.org/workshops/past-workshops/            past workshops</code></pre>
</div>
<p>You can find more detailed information about the BeautifulSoup
package and its full range of methods in the <a href="https://beautiful-soup-4.readthedocs.io/en/latest/" class="external-link">BeautifulSoup
Documentation</a>.</p>
</section><section><h2 class="section-heading" id="the-rights-wrongs-and-legal-barriers-to-scraping">The rights, wrongs, and legal barriers to scraping<a class="anchor" aria-label="anchor" href="#the-rights-wrongs-and-legal-barriers-to-scraping"></a>
</h2>
<hr class="half-width">
<p>The internet isn’t as open as it once was. What used to be a vast,
freely accessible source of information has become a valuable reservoir
of data —especially for training machine learning and generative AI
models. In response, many social media platforms and website owners have
either started monetizing access to their data or taken steps to protect
their resources from being overwhelmed by automated bots.</p>
<p>As a result, it’s increasingly common for websites to include
explicit prohibitions against web scraping in their Terms of Service
(TOS). To avoid legal or ethical issues, it’s essential to check both
the TOS and the site’s <code>robots.txt</code> file before scraping.</p>
<p>You can usually find a site’s <code>robots.txt</code> file by
appending <code>/robots.txt</code> to the root of the domain—for
example: <code>https://facebook.com/robots.txt</code> (not
<code>https://facebook.com/user/robots.txt</code>). Both the TOS and
<code>robots.txt</code> will help you understand what is allowed and
what isn’t, so it’s important to review them carefully before
proceeding.</p>
<div id="discussion1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Visit <a href="https://www.facebook.com/terms.php" class="external-link">Facebook’s Terms
of Service</a> and its <a href="https://facebook.com/robots.txt" class="external-link">robots.txt file</a>. What do they
say about web scraping or collecting data using automated means? Compare
it to <a href="https://redditinc.com/policies/user-agreement" class="external-link">Reddit’s
TOS</a> and <a href="https://www.reddit.com/robots.txt" class="external-link">Reddit’s
robots.txt</a>.</p>
</div>
</div>
</div>
<p>In addition to reviewing a website’s policies, you should also be
aware of the laws that apply in your region —especially those related to
copyright and data privacy. If you’re planning to collect a large amount
of data for research or commercial purposes, it’s a good idea to seek
legal advice before proceeding. If you’re affiliated with a university,
there’s a good chance it has a copyright office or legal team that can
help you navigate the legal aspects of your project. The university
library is often a great starting point for finding support and guidance
on copyright and data use.</p>
<p>To conclude, here is a brief code of conduct you should keep in mind
when doing web scraping:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Ask nicely whether you can access the data in another
way</strong>. If your project relies on data from a particular
organization, consider reaching out to them directly or checking whether
they provide an API. With a bit of luck, they might offer the data you
need in a structured format —saving you time and effort.</p></li>
<li>
<p><strong>Don’t download content that’s clearly not
public</strong>. For example, academic journal publishers often impose
strict usage restrictions on their databases. Mass-downloading PDFs can
violate these rules and may get you —or your university librarian— into
trouble.</p>
<p>If you need local copies for a legitimate reason (e.g., text mining),
special agreements may be possible. Your university library is a good
place to start exploring those options.</p>
</li>
<li><p><strong>Check your local legislation</strong>. Many countries
have laws protecting personal information, such as email addresses or
phone numbers. Even if this data is visible on a website, scraping it
could be illegal depending on your jurisdiction (e.g., in
Australia).</p></li>
<li><p><strong>Don’t share scraped content illegally</strong>. Scraping
for personal use is often considered fair use, even when it involves
copyrighted material. But sharing that data —especially if you don’t
have the rights to distribute it— can be illegal.</p></li>
<li><p><strong>Share what you can</strong>. If the scraped data is
public domain or you’ve been granted permission to share it, consider
publishing it for others to reuse (e.g., on datahub.io). Also, if you
wrote a scraper to access it, sharing your code (e.g., on GitHub) can
help others learn from and build on your work.</p></li>
<li><p><strong>Publish your own data in a reusable way</strong>. Make it
easier for others by offering your data in open, software-agnostic
formats like CSV, JSON, or XML. Include metadata that describes the
content, origin, and intended use of the data. Ensure it’s accessible
and searchable by search engines.</p></li>
<li>
<p><strong>Don’t break the Internet</strong>. Some websites can’t
handle high volumes of requests. If your scraper is recursive (i.e., it
follows links), test it first on a small subset.</p>
<p>Be respectful by setting delays between requests and limiting the
rate of access. You’ll learn more about how to do this in the next
episode.</p>
</li>
</ol>
<p>Following these guidelines helps ensure that your scraping is
ethical, legal, and considerate of the broader web ecosystem.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Every website is built on an HTML document that structures its
content.</li>
<li>An HTML document is composed of elements, usually defined by an
opening <code>&lt;tag&gt;</code> and a closing
<code>&lt;/tag&gt;</code>.</li>
<li>Elements can have attributes that define their properties, written
as <code>&lt;tag attribute_name="value"&gt;</code>.</li>
<li>We can parse an HTML document using <code>BeautifulSoup()</code> and
search for elements with the <code>.find()</code> and
<code>.find_all()</code> methods.
<ul>
<li>We can extract the text inside an element with
<code>.get_text()</code> and access attribute values using
<code>.get("attribute_name")</code>.</li>
</ul>
</li>
<li>Always review and respect a website’s Terms of Service (TOS) before
scraping its content.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-a-real-website"><p>Content from <a href="a-real-website.html">Scraping a real website</a></p>
<hr>
<p>Last updated on 2025-06-10 |

        <a href="https://github.com/josenino95/web-scraping-python/edit/main/episodes/a-real-website.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can I get the data and information from a real website?</li>
<li>How can I start automating my web scraping tasks?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Use the <code>requests</code> package to retrieve the HTML content
of a website.</li>
<li>Navigate the tree structure behind an HTML document to extract the
information we need.</li>
<li>Understand how to avoid being blocked after sending too many
requests.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>It’s now time to extract information from an actual website: <a href="https://carpentries.org" class="external-link">https://carpentries.org</a>. We’ll focus
on retrieving data about upcoming and past workshops taught by The
Carpentries global community.</p>
<p>To give you a sense of how web scraping can be useful here, we might
use this data to analyze which countries have hosted the most workshops,
build a live dashboard showing recent trends in instruction, or even
create an app that notifies us when a new workshop is scheduled in our
region.</p>
<p>With the basic tools shown here, you can build similar apps and
analyses using the website(s) you’re interested in. But always keep in
mind the code of conduct from the previous episode, especially the first
point: there might be an easier and more appropriate way to access the
data you need.</p>
<p>In fact, for the example we’re about to explore, The Carpentries
provides a <a href="https://feeds.carpentries.org/full_list.html" class="external-link">list
of data feeds</a> that you can use to access information about upcoming
and past workshops directly.</p>
<section><h2 class="section-heading" id="requests-the-website-html">“Requests” the website HTML<a class="anchor" aria-label="anchor" href="#requests-the-website-html"></a>
</h2>
<hr class="half-width">
<p>In the previous episode we used a simple HTML document, not an actual
website. Now that we’re moving into a more realistic and complex
scenario, we’ll add another tool to our toolbox: the
<code>requests</code> package.</p>
<p>For this lesson, we’ll use <code>requests</code> solely to retrieve
the HTML content of a website. Keep in mind that <code>requests</code>
offers much more functionality, which you can explore in the <a href="https://requests.readthedocs.io/en/latest/" class="external-link">Requests package
documentation</a>.</p>
<p>We’ll be scraping The Carpentries website, specifically the pages
listing <a href="https://carpentries.org/workshops/upcoming-workshops/" class="external-link">upcoming</a>
and past workshops](<a href="https://carpentries.org/workshops/past-workshops/" class="external-link uri">https://carpentries.org/workshops/past-workshops/</a>). To
do that, we’ll first load the requests package and then use the
<code>.get(url)</code> function and the <code>.text</code> property to
fetch and store the HTML content of the page.</p>
<p>Additionally, to simplify our navigation through the HTML document,
we’ll use the <a href="https://docs.python.org/3/howto/regex.html" class="external-link">Regular
Expressions</a> module <code>re</code> to remove all newline characters
(<code>\n</code>) and their surrounding whitespace. You can think of
this as a pre-processing or cleaning step. While we won’t go into detail
here, you can explore more about the topic in this by <a href="https://librarycarpentry.org/lc-data-intro/01-regular-expressions.html" class="external-link">Library
Carpentry Introduction to Regular Expressions</a>.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># Loading libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">from</span> time <span class="im">import</span> sleep</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="co"># Getting the HTML from our desired URL as a text string</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a>url <span class="op">=</span> <span class="st">'https://carpentries.org/workshops/upcoming-workshops/'</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a>req <span class="op">=</span> requests.get(url).text</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a><span class="co"># Cleaning and printing the string</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>cleaned_req <span class="op">=</span> re.sub(<span class="vs">r'\s*\n\s*'</span>, <span class="st">''</span>, req).strip()</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a><span class="bu">print</span>(cleaned_req[<span class="dv">0</span>:<span class="dv">1000</span>])</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>&lt;!doctype html&gt;&lt;html class=scroll-smooth lang=en-us dir=ltr&gt;&lt;head&gt;&lt;meta charset=utf-8&gt;&lt;meta name=viewport content="width=device-width"&gt;&lt;title&gt;Upcoming workshops | The Carpentries&lt;/title&gt;&lt;link rel=preconnect href=https://fonts.googleapis.com&gt;&lt;link rel=preconnect href=https://fonts.gstatic.com crossorigin&gt;&lt;link href="https://fonts.googleapis.com/css2?family=Mulish:ital,wght@0,200..1000;1,200..1000&amp;display=swap" rel=stylesheet&gt;&lt;script defer src=https://cdn.jsdelivr.net/npm/@glidejs/glide@3.5.x&gt;&lt;/script&gt;&lt;script src=https://kit.fontawesome.com/3a6fac633d.js crossorigin=anonymous&gt;&lt;/script&gt;&lt;link rel=stylesheet href=https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css&gt;&lt;script src=https://code.jquery.com/jquery-3.7.1.min.js&gt;&lt;/script&gt;&lt;script src=https://cdn.datatables.net/1.13.6/js/jquery.dataTables.min.js&gt;&lt;/script&gt;&lt;script src=https://cdn.jsdelivr.net/npm/moment@2.29.1/moment.min.js&gt;&lt;/script&gt;&lt;script src=https://cdn.datatables.net/plug-ins/1.13.6/sorting/datetime-moment.js&gt;&lt;/script&gt;&lt;sc</code></pre>
</div>
<p>We truncated the output to show only the first 1000 characters of the
document, as it’s too long to display fully. Still, we can confirm it’s
HTML and notice some elements that weren’t present in the earlier
example, such as <code>&lt;meta&gt;</code>, <code>&lt;link&gt;</code>
and <code>&lt;script&gt;</code> tags.</p>
<p>There’s also another way to view the HTML behind a website directly
in your web browser. In Google Chrome, you can right-click anywhere on
the page (on a Mac, hold the Control key while clicking), then choose
“View page source” from the pop-up menu, as shown in the next image. If
you don’t see that option, try clicking elsewhere on the page. A new tab
will open showing the full HTML document for the site you were
viewing.</p>
<figure><img src="fig/view_page_source.png" alt="A screenshot of The Carpentries upcoming workshops website in the Google Chrome web browser, showing how to View page source" class="figure mx-auto d-block"></figure><p>In the HTML page source in your browser, you can scroll down to find
the first-level header (<code>&lt;h1&gt;</code>) with the text “Upcoming
workshops.” An easier way is to use the Find bar (press Ctrl + F on
Windows or Command + F on Mac) and search for “Upcoming workshops.”</p>
<p>From that point, you can read the surrounding HTML and compare it to
how the content appears on the rendered website. You’ll see how
formatting is handled through tags like unordered lists
(<code>&lt;ul&gt;</code>), list items (<code>&lt;li&gt;</code>),
paragraphs (<code>&lt;p&gt;</code>), and content divisions
(<code>&lt;div&gt;</code>).</p>
</section><section><h2 class="section-heading" id="finding-the-information-we-want">Finding the information we want<a class="anchor" aria-label="anchor" href="#finding-the-information-we-want"></a>
</h2>
<hr class="half-width">
<p>However, carefully reading the entire HTML document to understand its
structure and locate the workshop data would be time-consuming.
Fortunately, modern web browsers offer a helpful tool called “Inspect”.
With this tool, you can examine the specific HTML behind any element on
a webpage.</p>
<p>To use it, right-click on the element you’re interested in (or hold
the Control key and click, if you’re on a Mac), and then select
“Inspect” from the pop-up menu.</p>
<p>Let’s try this with the first item in the Upcoming Workshops list, as
shown in the screenshot below. (Keep in mind that your first listed
workshop might differ, since the page is updated frequently.)</p>
<figure><img src="fig/inspect_workshop.png" alt="A screenshot of Google Chrome web browser, showing how to use Inspect from the Chrome DevTools" class="figure mx-auto d-block"></figure><p>Using the Inspect feature opens DevTools on the side of your browser.
DevTools offers a suite of tools for inspecting, debugging, and
analyzing web pages in real-time. For this workshop, we’ll focus on just
one: the “Elements” tab.</p>
<p>If you selected the organization name to inspect (as shown in the
screenshot), you’ll see an anchor (<code>&lt;a&gt;</code>) element
highlighted in the Elements tab. Around it, as its parent, you’ll find a
third-level header marked by <code>&lt;h3&gt;</code> tags. This provides
a visual example of the tree-like structure we discussed earlier,
elements nested inside other elements.</p>
<p>Back in our code, we left off after retrieving the HTML behind the
website using the requests package and storing it in a variable named
<code>req</code>.</p>
<p>Now, we can use the <code>BeautifulSoup()</code> function to parse
that HTML, just like we did before. The code below shows how we create
the soup object and use <code>.find_all()</code> to locate all the
third-level headers (<code>&lt;h3&gt;</code>) in the page.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># Parsing the HTML with BeautifulSoup</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>soup <span class="op">=</span> BeautifulSoup(cleaned_req, <span class="st">'html.parser'</span>)</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="co"># Finding all third-level headers and doing a formatted print</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>h3_by_tag <span class="op">=</span> soup.find_all(<span class="st">'h3'</span>)</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of h3 elements found: "</span>, <span class="bu">len</span>(h3_by_tag))</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="cf">for</span> n, h3 <span class="kw">in</span> <span class="bu">enumerate</span>(h3_by_tag):</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Workshop #</span><span class="sc">{</span>n<span class="sc">}</span><span class="ss"> - </span><span class="sc">{</span>h3<span class="sc">.</span>get_text()<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
<p>Besides searching elements by tag, it’s often useful to search using
attributes like id or class. In our case, we can see the <code>h3</code>
elements have a class attribute with multiple values: “title text-base
md:text-[1.75rem] leading-[2.125rem] font-semibold”. This set of classes
is used to apply styling, and it can help us target all elements that
share the same formatting.</p>
<p>So instead of selecting all <code>&lt;h3&gt;</code> tags directly, we
can search for elements with this specific class using the
<code>class_</code> argument of <code>.find_all()</code>, like this:</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># An alternative using the "class" attribute, instead of the h3 tag</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>h3_by_class <span class="op">=</span> soup.find_all(class_<span class="op">=</span><span class="st">"title text-base md:text-[1.75rem] leading-[2.125rem] font-semibold"</span>)</span></code></pre>
</div>
<p>This will give us the same elements as before, but demonstrates how
to refine your search by class —an especially useful technique when
different parts of a webpage use the same tag but serve different
purposes.</p>
</section><section><h2 class="section-heading" id="extracting-data">Extracting data<a class="anchor" aria-label="anchor" href="#extracting-data"></a>
</h2>
<hr class="half-width">
<p>Let’s go back to our web browser. Using the “Inspect” tool, can you
identify the parent of the first <code>&lt;h3&gt;</code> element?</p>
<p>If you guessed a content division element (a <code>&lt;div&gt;</code>
tag), you’re right! But exactly which <code>&lt;div&gt;</code> among all
those in the HTML? You’ll notice that this parent <code>div</code>
stands out because it has a <code>class</code> attribute attribute with
the value “p-8 mb-5 border”.</p>
<p>The animation below illustrates that all the information for each
workshop is grouped within a <code>&lt;div&gt;</code> element marked by
that same class attribute. It also shows how the “Inspect” tool
highlights the relevant portion of the webpage when you hover over an
HTML element, making it easier to understand the structure and pinpoint
the content you want to extract.</p>
<figure><img src="fig/inspect_div_class.gif" alt="All workshop cards share a 'p-8 mb-5 border' class attribute." class="figure mx-auto d-block"></figure><p>Understanding the tree structure of the HTML will help us navigate it
and extract the information we want. Navigating this tree is also
something we can do with BeautifulSoup. For example, let’s find the
parent of the first <code>&lt;h3&gt;</code> element using the
<code>.parent</code> property. As expected, this will return the
<code>&lt;div&gt;</code> element with the class attribute “p-8 mb-5
border”.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># Get the parent of the first h3 element and prettify it</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>div_firsth3 <span class="op">=</span> h3_by_class[<span class="dv">0</span>].parent</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="bu">print</span>(div_firsth3.prettify())</span></code></pre>
</div>
<div id="accordionSpoiler1" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler1" aria-expanded="false" aria-controls="collapseSpoiler1">
  <h3 class="accordion-header" id="headingSpoiler1">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div> Python output </h3>
</button>
<div id="collapseSpoiler1" class="accordion-collapse collapse" aria-labelledby="headingSpoiler1" data-bs-parent="#accordionSpoiler1">
<div class="accordion-body">
<p>Remember, the output shown here is probably different than yours, as
the website is continuously updated.</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>&lt;div class="p-8 mb-5 border" data-country="Puerto Rico" data-curriculum="Software Carpentry (Shell, Git, R for Reproducible Scientific Analysis)" data-meeting="In Person" data-program="Software Carpentry"&gt;
 &lt;div class="flex mb-4 -mx-2"&gt;
  &lt;div class="flex items-center mx-2"&gt;
   &lt;img alt="" class="mx-1" src="/software.svg"/&gt;
   &lt;span class="text-[0.625rem] uppercase"&gt;
    Software Carpentry
   &lt;/span&gt;
  &lt;/div&gt;
  &lt;div class="flex items-center mx-2"&gt;
   &lt;img alt="" class="mr-1" height="20" src="/flags/pr.png" width="20"/&gt;
   &lt;span class="text-[0.625rem] uppercase"&gt;
    Puerto Rico
   &lt;/span&gt;
  &lt;/div&gt;
  &lt;div class="flex items-center mx-2"&gt;
   &lt;img alt="" class="mx-1" src="/In-Person.svg"/&gt;
   &lt;span class="text-[0.625rem] uppercase"&gt;
    In Person
   &lt;/span&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;h3 class="title text-base md:text-[1.75rem] leading-[2.125rem] font-semibold"&gt;
  &lt;a class="underline hover:text-blue-hover text-gray-dark" href="https://dept-ccom-uprrp.github.io/2025-06-04-uprrp-r/"&gt;
   University of Puerto Rico
  &lt;/a&gt;
 &lt;/h3&gt;
 &lt;div class="mb-5 text-lg font-semibold text-gray-mid"&gt;
  Software Carpentry (Shell, Git, R for Reproducible Scientific Analysis)
 &lt;/div&gt;
 &lt;div class="mb-2 text-xs"&gt;
  &lt;strong class="font-bold"&gt;
   Instructors
  &lt;/strong&gt;
  :
  &lt;span class="instructors"&gt;
   Humberto Ortiz-Zuazaga, Airined Montes Mercado
  &lt;/span&gt;
 &lt;/div&gt;
 &lt;div class="mb-4 text-xs"&gt;
  &lt;strong class="font-bold"&gt;
   Helpers
  &lt;/strong&gt;
  :
  &lt;span class="helpers"&gt;
   Isabel Rivera, Diana Buitrago Escobar, Yabdiel Ramos Valerio
  &lt;/span&gt;
 &lt;/div&gt;
 &lt;div class="text-sm font-semibold text-gray-mid"&gt;
  Jun 04 - Jun 10 2025
 &lt;/div&gt;
&lt;/div&gt;</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>Taking a careful look, we can start to detect where the information
we want is located and how to extract it in a structured way.</p>
<p>We already know the workshop host organization is inside the
<code>&lt;h3&gt;</code> element, and from there we can also get the
hyperlink to that specific workshop’s website. Within the parent
<code>&lt;div&gt;</code>, we can extract additional details such as the
curriculum, country, format (in-person or online), and program (Software
Carpentry, Data Carpentry, Library Carpentry, The Carpentries).</p>
<p>As shown in the previous episode, we can store all this information
in a Python dictionary, which we can later transform into a Pandas
DataFrame for easier analysis.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># Create an empty dictionary and fill it with the info we are interested in</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>dict_workshop <span class="op">=</span> {}</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>dict_workshop[<span class="st">'host'</span>] <span class="op">=</span> div_firsth3.find(<span class="st">'h3'</span>).get_text()</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>dict_workshop[<span class="st">'link'</span>] <span class="op">=</span> div_firsth3.find(<span class="st">'h3'</span>).find(<span class="st">'a'</span>).get(<span class="st">'href'</span>)</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>dict_workshop[<span class="st">'curriculum'</span>] <span class="op">=</span> div_firsth3.get(<span class="st">'data-curriculum'</span>)</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>dict_workshop[<span class="st">'country'</span>] <span class="op">=</span> div_firsth3.get(<span class="st">'data-country'</span>)</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>dict_workshop[<span class="st">'format'</span>] <span class="op">=</span> div_firsth3.get(<span class="st">'data-meeting'</span>)</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>dict_workshop[<span class="st">'program'</span>] <span class="op">=</span> div_firsth3.get(<span class="st">'data-program'</span>)</span></code></pre>
</div>
<p>Ok, that’s the code for extracting information about the first
workshop listed, but what about all other workshops? Loop time!</p>
<p>We’ll use the same logic of the previous code block. But first, we’ll
find all elements with the class “p-8 mb-5 border”, which we know are
the containers for each workshop.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co"># Find all divs that match a class attribute</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>divs <span class="op">=</span> soup.find_all(<span class="st">'div'</span>, class_<span class="op">=</span><span class="st">"p-8 mb-5 border"</span>)</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="co"># Create an empty list, and fill it with info on each of the workshops found</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>workshop_list <span class="op">=</span> []</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="cf">for</span> item <span class="kw">in</span> divs: </span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>    dict_workshop <span class="op">=</span> {}</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>    dict_workshop[<span class="st">'host'</span>] <span class="op">=</span> item.find(<span class="st">'h3'</span>).get_text()</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>    dict_workshop[<span class="st">'link'</span>] <span class="op">=</span> div_firsth3.find(<span class="st">'h3'</span>).find(<span class="st">'a'</span>).get(<span class="st">'href'</span>)</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>    dict_workshop[<span class="st">'curriculum'</span>] <span class="op">=</span> div_firsth3.get(<span class="st">'data-curriculum'</span>)</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>    dict_workshop[<span class="st">'country'</span>] <span class="op">=</span> div_firsth3.get(<span class="st">'data-country'</span>)</span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>    dict_workshop[<span class="st">'format'</span>] <span class="op">=</span> div_firsth3.get(<span class="st">'data-meeting'</span>)</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>    dict_workshop[<span class="st">'program'</span>] <span class="op">=</span> div_firsth3.get(<span class="st">'data-program'</span>)</span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>    workshop_list.append(dict_workshop)</span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a></span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a><span class="co"># Transform list into a DataFrame</span></span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a>upcomingworkshops_df <span class="op">=</span> pd.DataFrame(workshop_list)</span></code></pre>
</div>
<p>Great! We’ve finished our first scraping task on a real website. Be
aware that there are multiple ways of achieving the same result. For
example, instead of finding the <code>div</code> elements with the “p-8
mb-5 border” class attribute, we can find the container of all the
workshops, a <code>div</code> with a class attribute of “filtered”.
Then, we can use a while loop across all its children, each of these
being one workshop container. The rest of the code would be the
same.</p>
<div id="accordionSpoiler2" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler2" aria-expanded="false" aria-controls="collapseSpoiler2">
  <h3 class="accordion-header" id="headingSpoiler2">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div> Alternative code </h3>
</button>
<div id="collapseSpoiler2" class="accordion-collapse collapse" aria-labelledby="headingSpoiler2" data-bs-parent="#accordionSpoiler2">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># Find the container of all the workshops</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>container <span class="op">=</span> soup.find(<span class="st">'div'</span>, class_<span class="op">=</span><span class="st">"filtered"</span>)</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a><span class="co"># Use the .contents property to get all the children, and accessing the first element</span></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>child_div <span class="op">=</span> container.contents[<span class="dv">0</span>]</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>workshop_list <span class="op">=</span> []</span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a><span class="co"># Create an empty list, and fill it with info on each of the workshops found</span></span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a><span class="cf">while</span> child_div <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>    dict_workshop <span class="op">=</span> {}</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>    dict_workshop[<span class="st">'host'</span>] <span class="op">=</span> child_div.find(<span class="st">'h3'</span>).get_text()</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a>    dict_workshop[<span class="st">'link'</span>] <span class="op">=</span> child_div.find(<span class="st">'h3'</span>).find(<span class="st">'a'</span>).get(<span class="st">'href'</span>)</span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a>    dict_workshop[<span class="st">'curriculum'</span>] <span class="op">=</span> child_div.get(<span class="st">'data-curriculum'</span>)</span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a>    dict_workshop[<span class="st">'country'</span>] <span class="op">=</span> child_div.get(<span class="st">'data-country'</span>)</span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a>    dict_workshop[<span class="st">'format'</span>] <span class="op">=</span> child_div.get(<span class="st">'data-meeting'</span>)</span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a>    dict_workshop[<span class="st">'program'</span>] <span class="op">=</span> child_div.get(<span class="st">'data-program'</span>)</span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a>    workshop_list.append(dict_workshop)</span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" tabindex="-1"></a>    <span class="co"># Next iteration of the loop will be with the next sibling</span></span>
<span id="cb9-20"><a href="#cb9-20" tabindex="-1"></a>    child_div <span class="op">=</span> child_div.next_sibling</span>
<span id="cb9-21"><a href="#cb9-21" tabindex="-1"></a></span>
<span id="cb9-22"><a href="#cb9-22" tabindex="-1"></a><span class="co"># Transform list into a DataFrame</span></span>
<span id="cb9-23"><a href="#cb9-23" tabindex="-1"></a>upcomingworkshops_df <span class="op">=</span> pd.DataFrame(workshop_list)</span>
<span id="cb9-24"><a href="#cb9-24" tabindex="-1"></a>upcomingworkshops_df</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<p>A key takeaway from this exercise is that, when we want to scrape
data in a structured way, we have to spend some time getting to know how
the website is structured and how we can identify and extract only the
elements we are interested in.</p>
<div id="challenge1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Extract the same information as in the previous exercise, but this
time from the Past Workshops Page at <a href="https://carpentries.org/past_workshops/" class="external-link">https://carpentries.org/past_workshops/</a>.
Which 5 countries have held the most workshops, and how many has each
held?</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>We can reuse directly the code we wrote before, changing only the URL
we got the HTML from.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co"># Get HTML and parse it with BeautifulSoup</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>url_past <span class="op">=</span> <span class="st">'https://carpentries.org/workshops/past-workshops/'</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>req_past <span class="op">=</span> requests.get(url_past).text</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>soup_past <span class="op">=</span> BeautifulSoup(req_past, <span class="st">'html.parser'</span>)</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a><span class="co"># Find all divs that match a class attribute</span></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>divs_past <span class="op">=</span> soup_past.find_all(<span class="st">'div'</span>, class_<span class="op">=</span><span class="st">"p-8 mb-5 border"</span>)</span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a><span class="co"># Create an empty list, and fill it with info on each of the workshops found</span></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a>workshop_list <span class="op">=</span> []</span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a><span class="cf">for</span> item <span class="kw">in</span> divs_past:</span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>    dict_workshop <span class="op">=</span> {}</span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>    dict_workshop[<span class="st">'host'</span>] <span class="op">=</span> item.find(<span class="st">'h3'</span>).get_text()</span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a>    dict_workshop[<span class="st">'link'</span>] <span class="op">=</span> item.find(<span class="st">'h3'</span>).find(<span class="st">'a'</span>).get(<span class="st">'href'</span>)</span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a>    dict_workshop[<span class="st">'curriculum'</span>] <span class="op">=</span> item.get(<span class="st">'data-curriculum'</span>)</span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a>    dict_workshop[<span class="st">'country'</span>] <span class="op">=</span> item.get(<span class="st">'data-country'</span>)</span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a>    dict_workshop[<span class="st">'format'</span>] <span class="op">=</span> item.get(<span class="st">'data-meeting'</span>)</span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>    dict_workshop[<span class="st">'program'</span>] <span class="op">=</span> item.get(<span class="st">'data-program'</span>)</span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a>    workshop_list.append(dict_workshop)</span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a></span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a><span class="co"># Transform list into a DataFrame</span></span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a>pastworkshops_df  <span class="op">=</span> pd.DataFrame(workshop_list)</span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a></span>
<span id="cb10-25"><a href="#cb10-25" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Total number of workshops in the table: '</span>, <span class="bu">len</span>(pastworkshops_df))</span>
<span id="cb10-26"><a href="#cb10-26" tabindex="-1"></a></span>
<span id="cb10-27"><a href="#cb10-27" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Top 5 of countries by number of workshops held: </span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb10-28"><a href="#cb10-28" tabindex="-1"></a>      pastworkshops_df[<span class="st">'country'</span>].value_counts().head())</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="challenge2" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>From the same upcoming workshops website, modify the code to also
extract the list of instructors, helpers, and the dates of the
workshops.</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>Instructors appear to be inside a <code>span</code> element
identified with the “instructors” class attribute. Similarly for
helpers. Workshop dates are inside a <code>div</code> element, with a
class attribute of value “text-sm font-semibold text-gray-mid”. We only
need to add three lines to our loop, and this is how it would look
like.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="cf">for</span> item <span class="kw">in</span> divs: </span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>    dict_workshop <span class="op">=</span> {}</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>    dict_workshop[<span class="st">'host'</span>] <span class="op">=</span> item.find(<span class="st">'h3'</span>).get_text()</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>    dict_workshop[<span class="st">'link'</span>] <span class="op">=</span> item.find(<span class="st">'h3'</span>).find(<span class="st">'a'</span>)[<span class="st">'href'</span>]</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>    dict_workshop[<span class="st">'curriculum'</span>] <span class="op">=</span> item.get(<span class="st">'data-curriculum'</span>)</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>    dict_workshop[<span class="st">'country'</span>] <span class="op">=</span> item.get(<span class="st">'data-country'</span>)</span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>    dict_workshop[<span class="st">'format'</span>] <span class="op">=</span> item.get(<span class="st">'data-meeting'</span>)</span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>    dict_workshop[<span class="st">'program'</span>] <span class="op">=</span> item.get(<span class="st">'data-program'</span>)</span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>    dict_workshop[<span class="st">'instructor'</span>] <span class="op">=</span> item.find(<span class="st">'span'</span>, class_ <span class="op">=</span> <span class="st">"instructors"</span>).get_text() <span class="cf">if</span> item.find(<span class="st">'span'</span>, class_ <span class="op">=</span> <span class="st">"instructors"</span>) <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="st">''</span></span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>    dict_workshop[<span class="st">'helper'</span>] <span class="op">=</span> item.find(<span class="st">'span'</span>, class_ <span class="op">=</span> <span class="st">"helpers"</span>).get_text() <span class="cf">if</span> item.find(<span class="st">'span'</span>, class_ <span class="op">=</span> <span class="st">"helpers"</span>) <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="st">''</span></span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a>    dict_workshop[<span class="st">'date'</span>] <span class="op">=</span> item.find(<span class="st">'div'</span>, class_ <span class="op">=</span> <span class="st">"text-sm font-semibold text-gray-mid"</span>).get_text()</span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a>    workshop_list.append(dict_workshop)</span></code></pre>
</div>
<p>You’ll notice the extra <code>if ... else</code> statements in the
instructor and helper extraction. This avoids the code to show an error
if the instructors or helpers are not listed in the workshop, and
therefore BeautifulSoup can find them in the HTML.</p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="automating-data-collection">Automating data collection<a class="anchor" aria-label="anchor" href="#automating-data-collection"></a>
</h2>
<hr class="half-width">
<p>Until now, we’ve only scraped one website page at a time. However,
sometimes the information you need is spread across multiple pages, or
you may need to follow a trail of hyperlinks. With the tools we’ve
learned so far, handling this task is straightforward. You would simply
add a loop that navigates to each page, fetches the HTML using the
<code>requests</code> package, and parses it with
<code>BeautifulSoup</code> to extract the necessary data.</p>
<p>An important consideration when doing this is to include a wait time
between each request to avoid overloading the web server providing the
data. Sending too many requests in a short period can disrupt access for
other users or even cause the server to crash. If the website detects
excessive requests, it might block your IP address to visit the website
or, in extreme cases, take legal action.</p>
<p>To prevent this, you can use Python’s built-in <code>time</code>
module and its <code>sleep()</code> function to pause between requests.
The <code>sleep()</code> function makes Python wait for a specified
number of seconds before moving on to the next line of code. For
example, the following code pauses for 10 seconds between each print
statement.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="im">from</span> time <span class="im">import</span> sleep</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'First'</span>)</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>sleep(<span class="dv">10</span>)</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Second'</span>)</span></code></pre>
</div>
<p>Let’s incorporate this important principle as we extract additional
information from each workshop’s individual website. We already have our
<code>upcomingworkshops_df</code> DataFrame, which includes a
<code>link</code> column containing the URL for each workshop’s webpage.
For example, let’s make a request to retrieve the HTML of the first
workshop in the DataFrame and take a look.</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="co"># Get the first link from the upcominworkshops dataframe</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>first_url <span class="op">=</span> upcomingworkshops_df.loc[<span class="dv">0</span>, <span class="st">'link'</span>]</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"URL we are visiting: "</span>, first_url)</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a><span class="co"># Retrieve the HTML</span></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a>req <span class="op">=</span> requests.get(first_url).text</span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a>cleaned_req <span class="op">=</span> re.sub(<span class="vs">r'\s*\n\s*'</span>, <span class="st">''</span>, req).strip()</span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a><span class="co"># Parse the HTML</span></span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a>soup <span class="op">=</span> BeautifulSoup(cleaned_req, <span class="st">'html.parser'</span>)</span></code></pre>
</div>
<p>If we explore the HTML using the ‘View page source’ or ‘Inspect’
tools in the browser, we notice something interesting inside the
<code>&lt;head&gt;</code> element. Because this information is within
<code>&lt;head&gt;</code> rather than the <code>&lt;body&gt;</code>, it
won’t be displayed directly on the page, but the
<code>&lt;meta&gt;</code> elements provide metadata that helps search
engines better understand, display, and index the page.</p>
<p>Each <code>&lt;meta&gt;</code> tag contain useful information for our
workshop table, for example, such as well-formatted start and end dates,
the exact location with latitude and longitude (for in-person
workshops), the language of instruction, and a structured listing of
instructors and helpers. These data points can be identified by the
“name” attribute of the <code>&lt;meta&gt;</code> tags, with the desired
information stored in their “content” attributes.</p>
<p>The following code automates extracting this data from each
workshop’s website, but only for the first five workshops in our
<code>upcomingworkshops_df</code> DataFrame. We limit it to five to
avoid sending too many requests at once and overwhelming the server,
though we could extend this to all workshops if needed.</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="co"># List of URLs in our dataframe</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>urls <span class="op">=</span> <span class="bu">list</span>(upcomingworkshops_df.loc[:<span class="dv">5</span>, <span class="st">'link'</span>])</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a><span class="co"># Start an empty list to store the different dictionaries with our data</span></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>list_of_workshops <span class="op">=</span> []</span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a><span class="co"># Start a loop over each URL</span></span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a><span class="cf">for</span> item <span class="kw">in</span> tqdm(urls):</span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a>    <span class="co"># Get the HTML and parse it</span></span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a>    req <span class="op">=</span> requests.get(item).text</span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a>    cleaned_req <span class="op">=</span> re.sub(<span class="vs">r'\s*\n\s*'</span>, <span class="st">''</span>, req).strip()</span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a>    soup <span class="op">=</span> BeautifulSoup(cleaned_req, <span class="st">'html.parser'</span>)</span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a>    <span class="co"># Start an empty dictionary and fill it with the URL, which</span></span>
<span id="cb14-15"><a href="#cb14-15" tabindex="-1"></a>    <span class="co"># is our identifier with our other dataframe</span></span>
<span id="cb14-16"><a href="#cb14-16" tabindex="-1"></a>    dict_w <span class="op">=</span> {}</span>
<span id="cb14-17"><a href="#cb14-17" tabindex="-1"></a>    dict_w[<span class="st">'link'</span>] <span class="op">=</span> item</span>
<span id="cb14-18"><a href="#cb14-18" tabindex="-1"></a></span>
<span id="cb14-19"><a href="#cb14-19" tabindex="-1"></a>    <span class="co"># Use the find function to search for the &lt;meta&gt; tag that </span></span>
<span id="cb14-20"><a href="#cb14-20" tabindex="-1"></a>    <span class="co"># has each specific 'name' attribute and get the value in the</span></span>
<span id="cb14-21"><a href="#cb14-21" tabindex="-1"></a>    <span class="co"># 'content' attribute</span></span>
<span id="cb14-22"><a href="#cb14-22" tabindex="-1"></a>    dict_w[<span class="st">'startdate'</span>] <span class="op">=</span> soup.find(<span class="st">'meta'</span>, attrs <span class="op">=</span> {<span class="st">'name'</span>: <span class="st">'startdate'</span>}).get(<span class="st">'content'</span>)</span>
<span id="cb14-23"><a href="#cb14-23" tabindex="-1"></a>    dict_w[<span class="st">'enddate'</span>] <span class="op">=</span> soup.find(<span class="st">'meta'</span>, attrs <span class="op">=</span> {<span class="st">'name'</span>: <span class="st">'enddate'</span>}).get(<span class="st">'content'</span>)</span>
<span id="cb14-24"><a href="#cb14-24" tabindex="-1"></a>    dict_w[<span class="st">'language'</span>] <span class="op">=</span> soup.find(<span class="st">'meta'</span>, attrs <span class="op">=</span> {<span class="st">'name'</span>: <span class="st">'language'</span>}).get(<span class="st">'content'</span>)</span>
<span id="cb14-25"><a href="#cb14-25" tabindex="-1"></a>    dict_w[<span class="st">'latlng'</span>] <span class="op">=</span> soup.find(<span class="st">'meta'</span>, attrs <span class="op">=</span> {<span class="st">'name'</span>: <span class="st">'latlng'</span>}).get(<span class="st">'content'</span>)</span>
<span id="cb14-26"><a href="#cb14-26" tabindex="-1"></a>    dict_w[<span class="st">'instructor'</span>] <span class="op">=</span> soup.find(<span class="st">'meta'</span>, attrs <span class="op">=</span> {<span class="st">'name'</span>: <span class="st">'instructor'</span>}).get(<span class="st">'content'</span>)</span>
<span id="cb14-27"><a href="#cb14-27" tabindex="-1"></a>    dict_w[<span class="st">'helper'</span>] <span class="op">=</span> soup.find(<span class="st">'meta'</span>, attrs <span class="op">=</span> {<span class="st">'name'</span>: <span class="st">'helper'</span>}).get(<span class="st">'content'</span>)</span>
<span id="cb14-28"><a href="#cb14-28" tabindex="-1"></a></span>
<span id="cb14-29"><a href="#cb14-29" tabindex="-1"></a>    <span class="co"># Append to our list</span></span>
<span id="cb14-30"><a href="#cb14-30" tabindex="-1"></a>    list_of_workshops.append(dict_w)</span>
<span id="cb14-31"><a href="#cb14-31" tabindex="-1"></a></span>
<span id="cb14-32"><a href="#cb14-32" tabindex="-1"></a>    <span class="co"># Be respectful, wait at least 3 seconds before a new request</span></span>
<span id="cb14-33"><a href="#cb14-33" tabindex="-1"></a>    sleep(<span class="dv">3</span>)</span>
<span id="cb14-34"><a href="#cb14-34" tabindex="-1"></a></span>
<span id="cb14-35"><a href="#cb14-35" tabindex="-1"></a>extradata_upcoming_df <span class="op">=</span> pd.DataFrame(list_of_workshops)</span></code></pre>
</div>
<div id="challenge3" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>It’s possible you encountered an error when running the previous code
block. The most likely cause is that the URL you tried to access doesn’t
exist. This is known as a 404 error, which means the requested page
cannot be found on the web server.</p>
<p>How would you approach handling this kind of error to make your
scraping process more robust?</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Show me the solution </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" aria-labelledby="headingSolution3" data-bs-parent="#accordionSolution3">
<div class="accordion-body">
<p>A straightforward Pythonic way to handle errors when accessing URLs
is to use a <a href="https://docs.python.org/3/tutorial/errors.html" class="external-link">try-except
block</a>. This allows you to catch any exceptions that occur when
trying to access a URL, ignore the problematic URL, and continue
processing the rest.</p>
<p>A cleaner approach is to check the actual HTTP response code returned
by the <code>requests</code> call. A status code of 200 means the
request was successful and the page exists. For any other response code,
you can choose to skip scraping that page and optionally log the code
for review.</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>req <span class="op">=</span> requests.get(url)</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>status_code <span class="op">=</span> response.status_code</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a><span class="cf">if</span> status_code <span class="op">==</span> <span class="dv">200</span>:</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>    <span class="co"># proceed with scraping</span></span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>    <span class="co"># handle or skip this URL</span></span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Use the requests package with
<code>requests.get('website_url').text</code> to retrieve the HTML
content of any website.</li>
<li>In your web browser, you can explore the HTML structure and identify
elements of interest using the “View Page Source” and “Inspect”
tools.</li>
<li>An HTML document is a nested tree of elements; navigate it by
accessing an element’s children (<code>.contents</code>), parent
(<code>.parent</code>), and siblings (<code>.next_sibling</code>,
<code>.previous_sibling</code>)</li>
<li>To avoid overwhelming a website’s server, add delays between
requests using the <code>sleep()</code> function from Python’s built-in
<code>time</code> module.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-dynamic-websites"><p>Content from <a href="dynamic-websites.html">Dynamic websites</a></p>
<hr>
<p>Last updated on 2025-06-10 |

        <a href="https://github.com/josenino95/web-scraping-python/edit/main/episodes/dynamic-websites.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are the differences between static and dynamic websites?</li>
<li>Why is it important to understand these differences when doing web
scraping?</li>
<li>How can I start my own web scraping project?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Use the <code>Selenium</code> package to scrape dynamic
websites.</li>
<li>Understand the usual pipeline of a web scraping project.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>Visit this practice webpage created by Hartley Brody for learning and
practicing web scraping: <a href="https://www.scrapethissite.com/pages/ajax-javascript/" class="external-link">https://www.scrapethissite.com/pages/ajax-javascript/</a>
(but first, read the <a href="https://www.scrapethissite.com/faq/" class="external-link">terms
of use</a>). Select “2015” to display that year’s Oscar-winning films.
Now try viewing the HTML behind the page, either using the View Page
Source tool in your browser or by using Python with the requests and
BeautifulSoup packages, as we’ve learned.</p>
<p>Can you find the Best Picture winner Spotlight anywhere in the HTML?
Can you find any of the other movies or the data from the table? If not,
how could you scrape this page?</p>
<p>When you explore a page like this, you’ll notice that the movie data
(including the title Spotlight) isn’t present in the initial HTML
source. That’s because the website uses <strong>JavaScript</strong> to
load the information dynamically. JavaScript is a programming language
that runs in your browser and allows websites to fetch, process, and
display content on the fly — often in response to user actions, like
clicking a button.</p>
<p>When you select “2015”, your browser runs JavaScript (triggered by
one of the <code>&lt;script&gt;</code> elements in the HTML) to retrieve
the relevant movie information from the web server and dynamically
update the table. This makes the page feel more interactive, but it also
means that the initial HTML you see doesn’t contain the movie data
itself.</p>
<p>You can observe this difference when using the “View page source” and
“Inspect” tools in your browser: “View page source” shows the original
HTML sent by the server, before any JavaScript runs. “Inspect” shows the
rendered HTML, after JavaScript has executed and updated the page
content.</p>
<p>Because the requests package only retrieves the original source HTML,
it won’t work for scraping pages like this. To scrape content that is
generated dynamically by JavaScript, we’ll use a different tool: the
<code>Selenium</code> package.</p>
<section><h2 class="section-heading" id="using-selenium-to-scrape-dynamic-websites">Using Selenium to scrape dynamic websites<a class="anchor" aria-label="anchor" href="#using-selenium-to-scrape-dynamic-websites"></a>
</h2>
<hr class="half-width">
<p><a href="https://www.selenium.dev/" class="external-link">Selenium</a> is an open-source
project for web browser automation. It’s especially useful for scraping
tasks because it behaves like a real user interacting with a web page in
a browser.</p>
<p>With Selenium, the browser actually renders the page, allowing
JavaScript to run and load any dynamic content. This means we can access
the fully loaded HTML (just like we’d see using the “Inspect” tool)
after JavaScript has executed.</p>
<p>In addition, Selenium can simulate real user interactions like
filling in text boxes, clicking buttons, scrolling, or selecting items
from drop-down menus. These features are essential when scraping dynamic
websites.</p>
<p>To get started, we’ll load the <code>webdriver</code> and
<code>By</code> components from the selenium package:</p>
<ul>
<li><p><code>webdriver</code> lets us launch or simulate a web browser
and interact with it through code.</p></li>
<li><p><code>By</code> helps us specify how we want to locate elements
in the HTML, by tag name (<code>By.TAG_NAME</code>), class
(<code>By.CLASS_NAME</code>), ID (<code>By.ID</code>), name
(<code>By.NAME</code>), and more.</p></li>
</ul>
<p>We’ll also continue using the other packages introduced in the
previous episode.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># Loading libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">from</span> time <span class="im">import</span> sleep</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">from</span> selenium <span class="im">import</span> webdriver</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">from</span> selenium.webdriver.common.by <span class="im">import</span> By</span></code></pre>
</div>
<p>Selenium can simulate different browsers like Chrome, Firefox,
Safari, and others. For now, we’ll use Chrome. When you run the
following line of code, a new Google Chrome window will open. Don’t
close it, this is the browser that Selenium is controlling to interact
with the webpage.</p>
<p>Later in the lesson, we’ll learn how to run headless browser
sessions. Headless means the browser runs in the background without
opening a visible window or user interface, which is useful for
automation tasks and running scripts on servers. To direct the browser
to the Oscar winners page, use the <code>.get()</code> method on the
<code>driver</code> object we just created.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># Open a Chrome web browser driven by Selenium</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>driver <span class="op">=</span> webdriver.Chrome()</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="co"># Go to a specific website</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>driver.get(<span class="st">"https://www.scrapethissite.com/pages/ajax-javascript/"</span>)</span></code></pre>
</div>
<p>How can we direct Selenium to click the “2015” text so the table for
that year appears? First, we need to locate that element, similar to how
we used <code>.find()</code> and <code>.find_all()</code> with
BeautifulSoup. In Selenium, we use <code>.find_element()</code> to get
the first matching element, and <code>.find_elements()</code> to get all
matches. However, the syntax for specifying search parameters is
slightly different.</p>
<p>For example:</p>
<ul>
<li><p>To select the first <code>&lt;table&gt;</code> element, you’d
use:
<code>driver.find_element(by=By.TAG_NAME, value="table")</code></p></li>
<li><p>To find a row with <code>&lt;tr class="film"&gt;</code>, you’d
use:
<code>driver.find_element(by=By.CLASS_NAME, value="film")</code></p></li>
</ul>
<p>To find the specific element that triggers the display of 2015’s
Oscar winners, use the “Inspect” tool in Chrome. Right-click on the
“2015” text and choose “Inspect.” In the DevTools panel, you’ll see this
HTML element:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">HTML<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode html" tabindex="0"><code class="sourceCode html"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">a</span><span class="ot"> href</span><span class="op">=</span><span class="st">"#"</span><span class="ot"> class</span><span class="op">=</span><span class="st">"year-link"</span><span class="ot"> id</span><span class="op">=</span><span class="st">"2015"</span><span class="dt">&gt;</span>2015<span class="dt">&lt;/</span><span class="kw">a</span><span class="dt">&gt;</span></span></code></pre>
</div>
<figure><img src="fig/inspect_element.PNG" alt="A screenshot of Google Chrome web browser, showing how to search a specific element by using Inspect from the Chrome DevTools" class="figure mx-auto d-block"></figure><p>Because the <code>id</code> attribute is unique, we can select this
element directly using:</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># Find 2015 element button</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>button_2015 <span class="op">=</span> driver.find_element(by<span class="op">=</span>By.ID, value<span class="op">=</span><span class="st">"2015"</span>)</span></code></pre>
</div>
<p>We’ve located the hyperlink element we need to click to display the
table for that year, and we’ll use the <code>.click()</code> method to
interact with it. Since the table takes a couple of seconds to load,
we’ll use the <code>sleep()</code> function to pause while the
JavaScript runs and the table loads. Next, we’ll use driver.page_source
to retrieve the updated HTML content from the website and store it in a
variable called <code>html_2015</code>. Finally, we’ll close the browser
window Selenium opened using <code>driver.quit()</code>.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># Click 2015 button</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>button_2015.click()</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="co"># Wait for table to load</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>sleep(<span class="dv">3</span>)</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a><span class="co"># Retrieve page HTML</span></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>html_2015 <span class="op">=</span> driver.page_source</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a><span class="co"># Close web browser</span></span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>driver.quit()</span></code></pre>
</div>
<p>Importantly, the HTML document we stored in <code>html_2015</code>
<strong>is the HTML after the dynamic content loaded</strong>. This
content wasn’t present in the original HTML and wouldn’t be accessible
if we had used the requests package alone.</p>
<p>While we could continue using Selenium’s <code>.find_element()</code>
and <code>.find_elements()</code> methods to extract the data, we’ll
switch back to BeautifulSoup to parse the HTML and locate elements,
since we already have practice with it. For example, if we search for
the first element with the class attribute “film” and retrieve its text,
we’ll see that the HTML now includes the movie “Spotlight.”</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># Parse HTML and </span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>soup <span class="op">=</span> BeautifulSoup(html_2015, <span class="st">'html.parser'</span>)</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="bu">print</span>(soup.find(class_<span class="op">=</span><span class="st">'film'</span>).prettify())</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>&lt;tr class="film"&gt;
 &lt;td class="film-title"&gt;
  Spotlight
 &lt;/td&gt;
 &lt;td class="film-nominations"&gt;
  6
 &lt;/td&gt;
 &lt;td class="film-awards"&gt;
  2
 &lt;/td&gt;
 &lt;td class="film-best-picture"&gt;
  &lt;i class="glyphicon glyphicon-flag"&gt;
  &lt;/i&gt;
 &lt;/td&gt;
&lt;/tr&gt;</code></pre>
</div>
<p>The following code repeats the process of clicking and loading the
2015 data, but now in “headless” mode (meaning the browser runs in the
background without opening a visible window). After the data loads, the
code extracts information from the table one column at a time, using the
fact that each column has a unique class attribute. Instead of writing
traditional for loops to extract the text from each element returned by
.find_all(), we use list comprehensions, which provide a more concise
way to generate lists. You can learn more about them reading <a href="https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions" class="external-link">Python’s
documentation on list comprehensions</a> or this <a href="https://www.programiz.com/python-programming/list-comprehension" class="external-link">short
tutorial by Programiz</a>.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co"># Create the Selenium webdriver and make it headless</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>options <span class="op">=</span> webdriver.ChromeOptions()</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>options.add_argument(<span class="st">"--headless=new"</span>)</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>driver <span class="op">=</span> webdriver.Chrome(options<span class="op">=</span>options)</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="co"># Load the website. Find and click 2015. Get post JavaScript execution HTML. Close webdriver</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>driver.get(<span class="st">"https://www.scrapethissite.com/pages/ajax-javascript/"</span>)</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>button_2015 <span class="op">=</span> driver.find_element(by<span class="op">=</span>By.ID, value<span class="op">=</span><span class="st">"2015"</span>)</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>button_2015.click()</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>sleep(<span class="dv">3</span>)</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>html_2015 <span class="op">=</span> driver.page_source</span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>driver.quit()</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a><span class="co"># Parse HTML using BeautifulSoup and extract each column as a list of values ising list comprehensions</span></span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>soup <span class="op">=</span> BeautifulSoup(html_2015, <span class="st">'html.parser'</span>)</span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>titles_lc <span class="op">=</span> [elem.get_text() <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(class_<span class="op">=</span><span class="st">"film-title"</span>)]</span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a>nominations_lc <span class="op">=</span> [elem.get_text() <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(class_<span class="op">=</span><span class="st">"film-nominations"</span>)]</span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a>awards_lc <span class="op">=</span> [elem.get_text() <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(class_<span class="op">=</span><span class="st">"film-awards"</span>)]</span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a><span class="co"># For the best picture column, we can't use .get_text() as there is no text</span></span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a><span class="co"># Rather, we want to see if there is an &lt;i&gt; tag</span></span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a>best_picture_lc <span class="op">=</span> [<span class="st">"Yes"</span> <span class="cf">if</span> elem.find(<span class="st">"i"</span>) <span class="op">==</span> <span class="va">None</span> <span class="cf">else</span> <span class="st">"No"</span> <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(class_<span class="op">=</span><span class="st">"film-best-picture"</span>)]</span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a><span class="co"># Create a dataframe based on the previous lists</span></span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a>movies_2015 <span class="op">=</span> pd.DataFrame(</span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a>    {<span class="st">'titles'</span>: titles_lc, <span class="st">'nominations'</span>: nominations_lc, <span class="st">'awards'</span>: awards_lc, <span class="st">'best_picture'</span>: best_picture_lc}</span>
<span id="cb8-27"><a href="#cb8-27" tabindex="-1"></a>)</span></code></pre>
</div>
<div id="challenge1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Using what we’ve learned in this episode, write a Python script that
collects Oscar-winning film data for all years from 2010 to 2015 from <a href="https://www.scrapethissite.com/pages/ajax-javascript/" class="external-link">Hartley
Brody’s website</a>. Hint: Reuse the code you wrote to scrape the 2015
data, and place it inside a loop that goes through each year.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>In addition to looping through each year, the following solution
changes the code by defining two functions: one that finds and clicks on
a year and returns the HTML after the data loads, and another that takes
this HTML, parses it, and extracts the data into a DataFrame.</p>
<p>To let you observe how Selenium opens the browser and interacts with
the page, this version does not use the “headless” option.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># Function to search year hyperlink and click it</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a><span class="kw">def</span> findyear_click_gethtml(year):</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>    button <span class="op">=</span> driver.find_element(by<span class="op">=</span>By.ID, value<span class="op">=</span>year)</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>    button.click()</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>    sleep(<span class="dv">3</span>)</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>    html <span class="op">=</span> driver.page_source</span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>    <span class="cf">return</span> html</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a><span class="co"># Function to parse html, extract table data, and assign year column</span></span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a><span class="kw">def</span> parsehtml_extractdata(html, year):</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>    soup <span class="op">=</span> BeautifulSoup(html, <span class="st">'html.parser'</span>)</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a>    titles_lc <span class="op">=</span> [elem.get_text() <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(class_<span class="op">=</span><span class="st">"film-title"</span>)]</span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a>    nominations_lc <span class="op">=</span> [elem.get_text() <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(class_<span class="op">=</span><span class="st">"film-nominations"</span>)]</span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a>    awards_lc <span class="op">=</span> [elem.get_text() <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(class_<span class="op">=</span><span class="st">"film-awards"</span>)]</span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a>    best_picture_lc <span class="op">=</span> [<span class="st">"No"</span> <span class="cf">if</span> elem.find(<span class="st">"i"</span>) <span class="op">==</span> <span class="va">None</span> <span class="cf">else</span> <span class="st">"Yes"</span> <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(class_<span class="op">=</span><span class="st">"film-best-picture"</span>)]</span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a>    movies_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a>        {<span class="st">'titles'</span>: titles_lc, <span class="st">'nominations'</span>: nominations_lc, <span class="st">'awards'</span>: awards_lc, <span class="st">'best_picture'</span>: best_picture_lc, <span class="st">'year'</span>: year}</span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a>    )</span>
<span id="cb9-19"><a href="#cb9-19" tabindex="-1"></a>    <span class="cf">return</span> movies_df</span>
<span id="cb9-20"><a href="#cb9-20" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" tabindex="-1"></a><span class="co"># Open Selenium webdriver and go to the page</span></span>
<span id="cb9-22"><a href="#cb9-22" tabindex="-1"></a>driver <span class="op">=</span> webdriver.Chrome()</span>
<span id="cb9-23"><a href="#cb9-23" tabindex="-1"></a>driver.get(<span class="st">"https://www.scrapethissite.com/pages/ajax-javascript/"</span>)</span>
<span id="cb9-24"><a href="#cb9-24" tabindex="-1"></a></span>
<span id="cb9-25"><a href="#cb9-25" tabindex="-1"></a><span class="co"># Create empty dataframe where we will append/concatenate the dataframes we get for each year</span></span>
<span id="cb9-26"><a href="#cb9-26" tabindex="-1"></a>result_df <span class="op">=</span> pd.DataFrame()</span>
<span id="cb9-27"><a href="#cb9-27" tabindex="-1"></a></span>
<span id="cb9-28"><a href="#cb9-28" tabindex="-1"></a><span class="cf">for</span> year <span class="kw">in</span> [<span class="st">"2010"</span>, <span class="st">"2011"</span>, <span class="st">"2012"</span>, <span class="st">"2013"</span>, <span class="st">"2014"</span>, <span class="st">"2015"</span>]:</span>
<span id="cb9-29"><a href="#cb9-29" tabindex="-1"></a>    html_year <span class="op">=</span> findyear_click_gethtml(year)</span>
<span id="cb9-30"><a href="#cb9-30" tabindex="-1"></a>    df_year <span class="op">=</span> parsehtml_extractdata(html_year, year)</span>
<span id="cb9-31"><a href="#cb9-31" tabindex="-1"></a>    result_df <span class="op">=</span> pd.concat([result_df, df_year])</span>
<span id="cb9-32"><a href="#cb9-32" tabindex="-1"></a></span>
<span id="cb9-33"><a href="#cb9-33" tabindex="-1"></a><span class="co"># Close the browser that Selenium opened</span></span>
<span id="cb9-34"><a href="#cb9-34" tabindex="-1"></a>driver.quit()</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="challenge2" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>If you’re ready for a break from scraping table data like we’ve done
in the last two episodes, try this new exercise to practice working with
dynamic websites. Visit <a href="https://www.scrapingcourse.com/javascript-rendering" class="external-link">this product
page</a> created by scrapingcourse.com and extract the name and price of
each product, along with the hyperlink from each product card to its
detailed view page.</p>
<p>Once you’ve done that, and if you’re up for an additional challenge,
visit each product’s detail page and scrape its SKU, Category, and
Description.</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>To identify the elements that contain the data you need, start by
using the “Inspect” tool in your browser. The screenshot below shows an
example from the website, where each product card is a
<code>&lt;div&gt;</code> element with several attributes that help
narrow down your search.</p>
<figure><img src="fig/product_cards_challenge.PNG" alt="A screenshot of Google Chrome web browser, highlighting the `&lt;div&gt;` element that contains the data we want about the product" class="figure mx-auto d-block"></figure><p>For instance, you can target these product cards by selecting
<code>&lt;div&gt;</code> elements with the attribute
<code>'data-testid'='product-item'</code>. Once you’ve found all the
relevant <code>&lt;div&gt;</code> elements, you can extract the
necessary information from each:</p>
<ul>
<li><p>Hyperlink: This is the <code>href</code> attribute of the
<code>&lt;a&gt;</code> tag within each product card.</p></li>
<li><p>Product name: This is inside a <code>&lt;span&gt;</code> tag with
the class attribute <code>'product-name'</code>.</p></li>
<li><p>Price: This is also inside a <code>&lt;span&gt;</code> tag, and
we can identify it using the attribute
<code>'data-content'='product-price'</code>.</p></li>
</ul>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co"># Open Selenium webdriver in headless mode and go to the desired page</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>options <span class="op">=</span> webdriver.ChromeOptions()</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>options.add_argument(<span class="st">"--headless=new"</span>)</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>driver <span class="op">=</span> webdriver.Chrome(options<span class="op">=</span>options)</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>driver.get(<span class="st">"https://www.scrapingcourse.com/javascript-rendering"</span>)</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a><span class="co"># As we don't have to click anything, just wait for the JavaScript to load, we can get the HTML right away</span></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>sleep(<span class="dv">3</span>)</span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>html <span class="op">=</span> driver.page_source</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a><span class="co"># Parste the HTML</span></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>soup <span class="op">=</span> BeautifulSoup(html, <span class="st">'html.parser'</span>)</span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a><span class="co"># Find all &lt;div&gt; elements that have a 'data-testid' attribute with the value of 'product-item'</span></span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>divs <span class="op">=</span> soup.find_all(<span class="st">"div"</span>, attrs <span class="op">=</span> {<span class="st">'data-testid'</span>: <span class="st">'product-item'</span>})</span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a><span class="co"># Loop through the &lt;div&gt; elements we found, and for each get the href,</span></span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a><span class="co"># the name (inside a &lt;span&gt; element with attribute class="product-name")</span></span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a><span class="co"># and the price (inside a &lt;span&gt; element with attribute data-content="product-price"</span></span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>list_of_dicts <span class="op">=</span> []</span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a><span class="cf">for</span> div <span class="kw">in</span> divs:</span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a>    <span class="co"># Create a dictionary to store the data we want for each product</span></span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a>    item_dict <span class="op">=</span> {</span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a>        <span class="st">'link'</span>: div.find(<span class="st">'a'</span>)[<span class="st">'href'</span>],</span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a>        <span class="st">'name'</span>: div.find(<span class="st">'span'</span>, attrs <span class="op">=</span> {<span class="st">'class'</span>: <span class="st">'product-name'</span>}).get_text(),</span>
<span id="cb10-25"><a href="#cb10-25" tabindex="-1"></a>        <span class="st">'price'</span>: div.find(<span class="st">'span'</span>, attrs <span class="op">=</span> {<span class="st">'data-content'</span>: <span class="st">'product-price'</span>}).get_text()</span>
<span id="cb10-26"><a href="#cb10-26" tabindex="-1"></a>    }</span>
<span id="cb10-27"><a href="#cb10-27" tabindex="-1"></a>    list_of_dicts.append(item_dict)</span>
<span id="cb10-28"><a href="#cb10-28" tabindex="-1"></a></span>
<span id="cb10-29"><a href="#cb10-29" tabindex="-1"></a>all_products <span class="op">=</span> pd.DataFrame(list_of_dicts)</span></code></pre>
</div>
<p>We could arrive to the same result if we replace the for loop with
list comprehensions. So here is another possible solution with that
approach.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>links <span class="op">=</span> [elem[<span class="st">'href'</span>] <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(<span class="st">'a'</span>, attrs <span class="op">=</span> {<span class="st">'class'</span>: <span class="st">'product-link'</span>})]</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>names <span class="op">=</span> [elem.get_text() <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(<span class="st">'span'</span>, attrs <span class="op">=</span> {<span class="st">'class'</span>: <span class="st">'product-name'</span>})]</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>prices <span class="op">=</span> [elem.get_text() <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(<span class="st">'span'</span>, attrs <span class="op">=</span> {<span class="st">'data-content'</span>: <span class="st">'product-price'</span>})]</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>all_products_v2 <span class="op">=</span> pd.DataFrame(</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>    {<span class="st">'link'</span>: links, <span class="st">'name'</span>: names, <span class="st">'price'</span>: prices}</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>)</span></code></pre>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="the-scraping-pipeline">The scraping pipeline<a class="anchor" aria-label="anchor" href="#the-scraping-pipeline"></a>
</h2>
<hr class="half-width">
<p>By now, you’ve learned the core tools for web scraping: requests,
BeautifulSoup, and Selenium. Together, these tools form a powerful and
flexible pipeline that can handle most scraping tasks. When starting a
new scraping project, following a few key steps will help ensure you
capture the data you need efficiently and responsibly.</p>
<p>The first step is to <strong>understand the structure of the
website</strong>. Every site organizes its content differently, so take
time to explore the page, inspect elements, and identify the HTML tags
and attributes that hold the information you’re after.</p>
<p>Next, <strong>determine whether the content is static or
dynamic</strong>. Static content is part of the initial HTML and can be
accessed directly using requests and parsed with BeautifulSoup. Dynamic
content, on the other hand, is loaded or updated by JavaScript after the
initial page load, and typically requires Selenium to render the page
fully before parsing.</p>
<p>Once you’ve identified how the content is delivered, <strong>build
your scraping pipeline</strong>. For static content, make a request
using <code>requests.get()</code> and pass the HTML to BeautifulSoup to
locate and extract the relevant elements. For dynamic pages, use
Selenium to open the page in a browser, interact with the page as needed
(e.g., clicking buttons, selecting dropdowns), and retrieve the updated
HTML with <code>driver.page_source</code>. Then use BeautifulSoup to
parse and extract the data.</p>
<p>Finally, <strong>clean, format, and store the data</strong> in a
structured format, such as a list of dictionaries or a Pandas DataFrame,
so it’s ready for analysis or export.</p>
<p>Following this pipeline helps you break down complex tasks into
clear, manageable steps and choose the right tools for the job With
practice, you’ll be able to adapt this process to scrape and organize
data from a wide range of websites.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Dynamic websites load content using JavaScript, so the data may not
be present in the initial HTML. It’s important to distinguish between
static and dynamic content when planning your scraping approach.</li>
<li>The <code>Selenium</code> package and its <code>webdriver</code>
module simulates a real browser, allowing you to execute JavaScript and
interact with the page as a user would —clicking, scrolling, or filling
out forms</li>
<li>Key Selenium commands:
<ul>
<li>
<code>webdriver.Chrome()</code>: Launch the Chrome browser
simulator</li>
<li>
<code>.get("website_url")</code>: Visit a given website</li>
<li>
<code>.find_element(by, value)</code> and
<code>.find_elements(by, value)</code>: Locate one or multiple
elements</li>
<li>
<code>.click()</code>: Click a selected element</li>
<li>
<code>.page_source</code>: Retrieve the full HTML after JavaScript
execution</li>
<li>
<code>.quit()</code>: Close the browser</li>
</ul>
</li>
<li>The browser’s “Inspect” tool allows users to view the HTML document
after dynamic content has loaded. This is useful for identifying which
elements contain the data you want to scrape.</li>
<li>A typical web scraping pipeline includes: 1) Understanding the
website structure; 2) Determining whether content is static or dynamic;
3) Choosing the right tools (requests + BeautifulSoup or Selenium); 4)
Extracting and cleaning the data; 5) Storing the data in a structured
format.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/josenino95/web-scraping-python/edit/main/README.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/josenino95/web-scraping-python/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/josenino95/web-scraping-python/" class="external-link">Source</a></p>
				<p><a href="https://github.com/josenino95/web-scraping-python/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:jose_nino@ucsb.edu">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.17.1" class="external-link">sandpaper (0.17.1)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.9" class="external-link">pegboard (0.7.9)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.7" class="external-link">varnish (1.0.7)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "LearningResource",
  "@id": "https://josenino95.github.io/web-scraping-python/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/LearningResource/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "web scraping, data, python, The Carpentries",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://josenino95.github.io/web-scraping-python/aio.html",
  "identifier": "https://josenino95.github.io/web-scraping-python/aio.html",
  "dateCreated": "2024-09-23",
  "dateModified": "2025-10-14",
  "datePublished": "2025-10-14"
}

  </script><script>
		feather.replace();
	</script>
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

